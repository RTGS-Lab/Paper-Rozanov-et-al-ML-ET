{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "411cc2ac-42f1-423f-8a41-c805a19619cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b354ec4b-524d-4741-a17f-afe46b61f0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import phik\n",
    "from phik.report import plot_correlation_matrix\n",
    "from phik import report\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from PM_eq import penman_monteith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b6b33f2-903b-4bd2-ad32-7f5c31393fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>LE_F_MDS</th>\n",
       "      <th>LE_F_MDS_QC</th>\n",
       "      <th>NETRAD</th>\n",
       "      <th>G_F_MDS</th>\n",
       "      <th>TA_F</th>\n",
       "      <th>VPD_F</th>\n",
       "      <th>WS_F</th>\n",
       "      <th>PA_F</th>\n",
       "      <th>site</th>\n",
       "      <th>H_F_MDS</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>IGBP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-05-24</td>\n",
       "      <td>19.2224</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>236.108854</td>\n",
       "      <td>-1.567770</td>\n",
       "      <td>11.213</td>\n",
       "      <td>10.345</td>\n",
       "      <td>1.841</td>\n",
       "      <td>98.421</td>\n",
       "      <td>FLX_US-Wi1</td>\n",
       "      <td>138.470000</td>\n",
       "      <td>46.7305</td>\n",
       "      <td>-91.2329</td>\n",
       "      <td>DBF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-05-25</td>\n",
       "      <td>24.2024</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>227.120214</td>\n",
       "      <td>-1.126670</td>\n",
       "      <td>12.308</td>\n",
       "      <td>10.551</td>\n",
       "      <td>1.835</td>\n",
       "      <td>98.471</td>\n",
       "      <td>FLX_US-Wi1</td>\n",
       "      <td>112.405000</td>\n",
       "      <td>46.7305</td>\n",
       "      <td>-91.2329</td>\n",
       "      <td>DBF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-05-26</td>\n",
       "      <td>19.4017</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>249.112486</td>\n",
       "      <td>0.019932</td>\n",
       "      <td>14.778</td>\n",
       "      <td>12.203</td>\n",
       "      <td>1.660</td>\n",
       "      <td>98.656</td>\n",
       "      <td>FLX_US-Wi1</td>\n",
       "      <td>108.937000</td>\n",
       "      <td>46.7305</td>\n",
       "      <td>-91.2329</td>\n",
       "      <td>DBF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-05-27</td>\n",
       "      <td>23.7468</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>244.104535</td>\n",
       "      <td>1.914990</td>\n",
       "      <td>18.154</td>\n",
       "      <td>15.802</td>\n",
       "      <td>1.532</td>\n",
       "      <td>98.265</td>\n",
       "      <td>FLX_US-Wi1</td>\n",
       "      <td>112.939000</td>\n",
       "      <td>46.7305</td>\n",
       "      <td>-91.2329</td>\n",
       "      <td>DBF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-05-28</td>\n",
       "      <td>42.2603</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>246.821474</td>\n",
       "      <td>0.114018</td>\n",
       "      <td>14.890</td>\n",
       "      <td>6.921</td>\n",
       "      <td>2.285</td>\n",
       "      <td>97.722</td>\n",
       "      <td>FLX_US-Wi1</td>\n",
       "      <td>85.043500</td>\n",
       "      <td>46.7305</td>\n",
       "      <td>-91.2329</td>\n",
       "      <td>DBF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155271</th>\n",
       "      <td>2003-09-11</td>\n",
       "      <td>55.7628</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>126.808894</td>\n",
       "      <td>7.353920</td>\n",
       "      <td>23.534</td>\n",
       "      <td>10.864</td>\n",
       "      <td>2.743</td>\n",
       "      <td>96.827</td>\n",
       "      <td>AMF_US-Wi3</td>\n",
       "      <td>15.796000</td>\n",
       "      <td>46.6347</td>\n",
       "      <td>-91.0987</td>\n",
       "      <td>DBF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155272</th>\n",
       "      <td>2003-09-13</td>\n",
       "      <td>31.6040</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>65.703064</td>\n",
       "      <td>-8.120460</td>\n",
       "      <td>15.390</td>\n",
       "      <td>2.544</td>\n",
       "      <td>1.353</td>\n",
       "      <td>96.572</td>\n",
       "      <td>AMF_US-Wi3</td>\n",
       "      <td>-8.821360</td>\n",
       "      <td>46.6347</td>\n",
       "      <td>-91.0987</td>\n",
       "      <td>DBF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155273</th>\n",
       "      <td>2003-09-14</td>\n",
       "      <td>54.2463</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>92.268000</td>\n",
       "      <td>-8.471200</td>\n",
       "      <td>13.966</td>\n",
       "      <td>4.375</td>\n",
       "      <td>1.341</td>\n",
       "      <td>96.912</td>\n",
       "      <td>AMF_US-Wi3</td>\n",
       "      <td>-10.596500</td>\n",
       "      <td>46.6347</td>\n",
       "      <td>-91.0987</td>\n",
       "      <td>DBF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155274</th>\n",
       "      <td>2003-09-15</td>\n",
       "      <td>44.2428</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>99.622415</td>\n",
       "      <td>-3.575530</td>\n",
       "      <td>12.401</td>\n",
       "      <td>3.585</td>\n",
       "      <td>1.304</td>\n",
       "      <td>96.968</td>\n",
       "      <td>AMF_US-Wi3</td>\n",
       "      <td>-0.490375</td>\n",
       "      <td>46.6347</td>\n",
       "      <td>-91.0987</td>\n",
       "      <td>DBF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155275</th>\n",
       "      <td>2003-09-16</td>\n",
       "      <td>51.6369</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>158.090267</td>\n",
       "      <td>6.221170</td>\n",
       "      <td>17.402</td>\n",
       "      <td>9.006</td>\n",
       "      <td>1.288</td>\n",
       "      <td>96.884</td>\n",
       "      <td>AMF_US-Wi3</td>\n",
       "      <td>17.500900</td>\n",
       "      <td>46.6347</td>\n",
       "      <td>-91.0987</td>\n",
       "      <td>DBF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100703 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        TIMESTAMP  LE_F_MDS  LE_F_MDS_QC      NETRAD   G_F_MDS    TA_F  \\\n",
       "0      2003-05-24   19.2224       1.0000  236.108854 -1.567770  11.213   \n",
       "1      2003-05-25   24.2024       1.0000  227.120214 -1.126670  12.308   \n",
       "2      2003-05-26   19.4017       0.9375  249.112486  0.019932  14.778   \n",
       "3      2003-05-27   23.7468       1.0000  244.104535  1.914990  18.154   \n",
       "4      2003-05-28   42.2603       0.9375  246.821474  0.114018  14.890   \n",
       "...           ...       ...          ...         ...       ...     ...   \n",
       "155271 2003-09-11   55.7628       1.0000  126.808894  7.353920  23.534   \n",
       "155272 2003-09-13   31.6040       1.0000   65.703064 -8.120460  15.390   \n",
       "155273 2003-09-14   54.2463       1.0000   92.268000 -8.471200  13.966   \n",
       "155274 2003-09-15   44.2428       1.0000   99.622415 -3.575530  12.401   \n",
       "155275 2003-09-16   51.6369       1.0000  158.090267  6.221170  17.402   \n",
       "\n",
       "         VPD_F   WS_F    PA_F        site     H_F_MDS      lat      lon IGBP  \n",
       "0       10.345  1.841  98.421  FLX_US-Wi1  138.470000  46.7305 -91.2329  DBF  \n",
       "1       10.551  1.835  98.471  FLX_US-Wi1  112.405000  46.7305 -91.2329  DBF  \n",
       "2       12.203  1.660  98.656  FLX_US-Wi1  108.937000  46.7305 -91.2329  DBF  \n",
       "3       15.802  1.532  98.265  FLX_US-Wi1  112.939000  46.7305 -91.2329  DBF  \n",
       "4        6.921  2.285  97.722  FLX_US-Wi1   85.043500  46.7305 -91.2329  DBF  \n",
       "...        ...    ...     ...         ...         ...      ...      ...  ...  \n",
       "155271  10.864  2.743  96.827  AMF_US-Wi3   15.796000  46.6347 -91.0987  DBF  \n",
       "155272   2.544  1.353  96.572  AMF_US-Wi3   -8.821360  46.6347 -91.0987  DBF  \n",
       "155273   4.375  1.341  96.912  AMF_US-Wi3  -10.596500  46.6347 -91.0987  DBF  \n",
       "155274   3.585  1.304  96.968  AMF_US-Wi3   -0.490375  46.6347 -91.0987  DBF  \n",
       "155275   9.006  1.288  96.884  AMF_US-Wi3   17.500900  46.6347 -91.0987  DBF  \n",
       "\n",
       "[100703 rows x 14 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod = np.load('./data_v02/MOD_features_all.npy', allow_pickle=True)\n",
    "mod_idxs = set(np.load('./data_v02/MOD_target_idx_all.npy', allow_pickle=True))\n",
    "\n",
    "fluxes = pd.read_csv('./data_v02/target_fluxes_MidWest_LE.csv')\n",
    "keep_idxs = [idx for idx in fluxes.index.tolist() if (idx in mod_idxs)]\n",
    "fluxes = fluxes.loc[keep_idxs,:]\n",
    "fluxes['TIMESTAMP'] = pd.to_datetime(fluxes.TIMESTAMP, format='%Y%m%d')\n",
    "targets = fluxes.LE_F_MDS.values\n",
    "\n",
    "fluxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac1ffc64-8c29-4f3f-b03e-3b665872d535",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_idxs = pd.Series(list(mod_idxs))\n",
    "mod_idxs.index = np.arange(len(mod_idxs))\n",
    "valid_feature_indices = mod_idxs[mod_idxs.isin(fluxes.index)].index.values\n",
    "mod_features = mod[valid_feature_indices]\n",
    "mod_features = mod_features[:,:,:-1]#Dropping Coarse_Resolution_Internal_CM\n",
    "\n",
    "NDVI = (mod_features[:,:,1] - mod_features[:,:,0])/(mod_features[:,:,1] + mod_features[:,:,0])\n",
    "EVI = (mod_features[:,:,1] - mod_features[:,:,0])/(mod_features[:,:,1] + 6*mod_features[:,:,0] - 7.5*mod_features[:,:,2] + 1)\n",
    "GNDVI = (mod_features[:,:,1] - mod_features[:,:,3])/(mod_features[:,:,1] + mod_features[:,:,3])\n",
    "SAVI = (mod_features[:,:,1] - mod_features[:,:,0])/(mod_features[:,:,1] + mod_features[:,:,0] + 0.5)*1.5\n",
    "ARVI = (mod_features[:,:,1] + mod_features[:,:,2] - 2*mod_features[:,:,0])/(mod_features[:,:,1] + mod_features[:,:,2] + 2*mod_features[:,:,0])\n",
    "\n",
    "pm_flux = penman_monteith(fluxes, fluxes.index, fluxes, mode='ground').values / 10\n",
    "\n",
    "features = np.concatenate([mod_features,\n",
    "                           NDVI[:,:, np.newaxis], EVI[:,:, np.newaxis], GNDVI[:,:, np.newaxis],\n",
    "                           SAVI[:,:, np.newaxis], ARVI[:,:, np.newaxis]], axis=2)\n",
    "\n",
    "mod_names = [\n",
    "          'SensorZenith', 'SensorAzimuth', 'SolarZenith', 'SolarAzimuth',\n",
    "         'sur_refl_b01', 'sur_refl_b02', 'sur_refl_b03', 'sur_refl_b04',\n",
    "         'sur_refl_b05', 'sur_refl_b06', 'sur_refl_b07', \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86aa772c-df53-4fd6-8a84-e10058a9f7b5",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36dad83a-d847-43db-94a4-461e90cc0b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size, dropout=0.1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)\n",
    "        \n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.fc(out[:, -1, :])  # Take the output from the last timestep\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1980f8-431a-4b90-92c1-3492760feee4",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4288a57b-096f-48b3-b416-2eef3aa3d299",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X, y, x_scaler=None, y_scaler=None, fit_scalers=False):\n",
    "        self.x_scaler = x_scaler if x_scaler else MinMaxScaler()\n",
    "        self.y_scaler = y_scaler if y_scaler else MinMaxScaler()\n",
    "\n",
    "        if fit_scalers: \n",
    "            print('fitting')\n",
    "            N, T, F = X.shape\n",
    "            X_reshaped = X.reshape(N, -1)  # Flatten time/feature dims\n",
    "            self.x_scaler.fit(X_reshaped)\n",
    "            self.y_scaler.fit(y)\n",
    "\n",
    "        # Transform data\n",
    "        N, T, F = X.shape\n",
    "        X_scaled = self.x_scaler.transform(X.reshape(N, -1)).reshape(N, T, F)\n",
    "        y_scaled = self.y_scaler.transform(y.reset_index().to_numpy()[:,1].reshape(-1, 1))\n",
    "        \n",
    "        self.X = torch.tensor(X_scaled, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y_scaled, dtype=torch.float32)\n",
    "        self.target_idx = torch.tensor(y.reset_index().to_numpy()[:,0].reshape(-1, 1), dtype=torch.int32)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx], self.target_idx[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad047a4e-8b9c-4447-8d96-b74d57ef8374",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, fluxes, test_size=0.3, random_state=42)\n",
    "\n",
    "y_train = y_train.LE_F_MDS#reshape(-1, 1)\n",
    "y_test = y_test.LE_F_MDS#reshape(-1, 1)\n",
    "\n",
    "x_scaler, y_scaler = MinMaxScaler(), MinMaxScaler()\n",
    "N, T, F = X_train.shape\n",
    "x_scaler.fit(X_train.reshape(N, -1))\n",
    "y_scaler.fit(y_train.reset_index().to_numpy()[:,1].reshape(-1, 1))\n",
    "\n",
    "train_dataset = CustomDataset(X_train, y_train, x_scaler, y_scaler, fit_scalers=False)\n",
    "test_dataset = CustomDataset(X_test, y_test, x_scaler, y_scaler, fit_scalers=False)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "444e4dc9-b6f6-400a-b34f-d3ec90dee233",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "num_epoch = 50\n",
    "\n",
    "input_size = 16 #num features\n",
    "hidden_size = 128\n",
    "num_layers = 2\n",
    "dropout=0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d24e7e9b-3bcf-45e5-bae7-7d41f86925c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LSTMModel(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, output_size=1, dropout=dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "92467b36-dacb-4ba3-bd56-6bfd1f5dd848",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0eaf07aa-7735-40d5-9192-044f65ad7fd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e1cf915ba284988824f95b51a2f05e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 26.450\t\tTest R2: 0.5643\t\t Test MAE: 19.3334\n",
      "Test RMSE: 22.483\t\tTest R2: 0.6852\t\t Test MAE: 15.2189\n",
      "Test RMSE: 21.106\t\tTest R2: 0.7226\t\t Test MAE: 14.1092\n",
      "Test RMSE: 20.852\t\tTest R2: 0.7292\t\t Test MAE: 14.0054\n",
      "Test RMSE: 20.630\t\tTest R2: 0.7350\t\t Test MAE: 13.8653\n",
      "Test RMSE: 20.687\t\tTest R2: 0.7335\t\t Test MAE: 14.1849\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      8\u001b[39m     error = criteria(pred, y)\n\u001b[32m     10\u001b[39m     optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[43merror\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m     optimizer.step()\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m epoch % \u001b[32m5\u001b[39m == \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/umn/GEMS/ET_LCCMR/.venv/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/umn/GEMS/ET_LCCMR/.venv/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/umn/GEMS/ET_LCCMR/.venv/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "best = -np.inf\n",
    "t0 = time.time()\n",
    "for epoch in tqdm(range(num_epoch)):\n",
    "    model.train()\n",
    "    for x, y, idx in train_loader:\n",
    "        x, y = x.to(torch.float32), y.to(torch.float32)\n",
    "        pred = model(x)\n",
    "        error = criteria(pred, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        error.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        model.eval()\n",
    "        test_preds = []\n",
    "        test_true = []\n",
    "        test_x = []\n",
    "        test_idx = []\n",
    "        with torch.no_grad():\n",
    "            for x, y, idx in test_loader:\n",
    "                x, y = x.to(torch.float32), y.to(torch.float32)\n",
    "                preds = model(x)\n",
    "                preds = train_dataset.y_scaler.inverse_transform(preds.detach().cpu())\n",
    "                y_scaled = train_dataset.y_scaler.inverse_transform(y.detach().cpu())\n",
    "                test_preds.append(torch.tensor(preds))\n",
    "                test_true.append(torch.tensor(y_scaled))\n",
    "\n",
    "        test_preds = torch.cat(test_preds).squeeze()\n",
    "        test_true = torch.cat(test_true).squeeze()\n",
    "        \n",
    "        test_loss = criteria(test_preds, test_true).item()\n",
    "        r2 = r2_score(test_true.numpy(), test_preds.numpy())\n",
    "        mae = mean_absolute_error(test_true.numpy(), test_preds.numpy())\n",
    "        #writer.add_scalar(\"Loss/test\", test_loss, epoch)\n",
    "        #writer.add_scalar(\"R2/test\", r2, epoch)\n",
    "        \n",
    "        best_old = best\n",
    "        best = min(test_loss, best)\n",
    "        if abs(best) > best_old:\n",
    "            torch.save(model.state_dict(), f'./models/LSTM.pth') #0.6532\n",
    "            #writer.add_text(\"Checkpoint\", \"Saved model at epoch {}\".format(epoch))\n",
    "        print(f'Test RMSE: {test_loss**0.5:0.3f}\\t\\tTest R2: {r2:0.4f}\\t\\t Test MAE: {mae:0.4f}')\n",
    "#writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50d48c59-9575-4f7a-b414-38986a9574b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6740939323066619"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
